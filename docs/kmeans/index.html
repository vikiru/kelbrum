<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-kmeans" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Data Clustering with K-means | Kelbrum</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://vikiru.github.io/kelbrum/kmeans/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="Kelbrum, anime, recommendation, engine, system, machine learning, tensorflow, similarity, kmeans, react, react router, tailwindcss, daisyui"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Data Clustering with K-means | Kelbrum"><meta data-rh="true" name="description" content="Data Clustering with K-means"><meta data-rh="true" property="og:description" content="Data Clustering with K-means"><link data-rh="true" rel="icon" href="/kelbrum/favicon.ico"><link data-rh="true" rel="canonical" href="https://vikiru.github.io/kelbrum/kmeans/"><link data-rh="true" rel="alternate" href="https://vikiru.github.io/kelbrum/kmeans/" hreflang="en"><link data-rh="true" rel="alternate" href="https://vikiru.github.io/kelbrum/kmeans/" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HX9JEL4XJY"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-HX9JEL4XJY",{anonymize_ip:!0})</script><link rel="stylesheet" href="/kelbrum/assets/css/styles.c949a413.css">
<script src="/kelbrum/assets/js/runtime~main.e3320e66.js" defer="defer"></script>
<script src="/kelbrum/assets/js/main.a50cc31a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/kelbrum/"><div class="navbar__logo"><img src="/kelbrum/logo.png" alt="Kelbrum Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/kelbrum/logo.png" alt="Kelbrum Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/kelbrum/features/">Features</a><a class="navbar__item navbar__link" href="/kelbrum/motivation/">Motivation</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/kelbrum/">Getting Started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/kelbrum/motivation/">Development</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kelbrum/motivation/">🔥 Motivation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kelbrum/development/">🔧 Development Overview</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kelbrum/stack/">🛠️ Tech Stack</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kelbrum/model/">🧩 Model Overview</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/kelbrum/normalize/">📏 Normalizing Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/kelbrum/kmeans/">Data Clustering with K-means</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/kelbrum/acknowledgments/">Conclusion</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/kelbrum/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Development</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Data Clustering with K-means</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Data Clustering with K-means</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="data-clustering-with-k-means">Data Clustering with K-means<a href="#data-clustering-with-k-means" class="hash-link" aria-label="Direct link to Data Clustering with K-means" title="Direct link to Data Clustering with K-means">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="identifying-clustering-algorithms">Identifying Clustering Algorithms<a href="#identifying-clustering-algorithms" class="hash-link" aria-label="Direct link to Identifying Clustering Algorithms" title="Direct link to Identifying Clustering Algorithms">​</a></h3>
<p>Once the data was <a href="/kelbrum/normalize/">normalized</a>, the next step was to figure out how to group the data based on their similarity. Upon researching this topic, I found out that there were several algorithms to achieve this such as:</p>
<ul>
<li><strong>K-means clustering</strong></li>
<li><strong>K-mediods clustering</strong></li>
<li><strong>K-nearest neighbors</strong></li>
<li><strong>Hierarchal clustering</strong></li>
<li><strong>DBSCAN</strong></li>
</ul>
<p>There were several other algorithms as well, however, I decided to use K-means clustering as I felt it was easier to understand and applicable for my use case.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="choosing-the-right-tools">Choosing the Right Tools<a href="#choosing-the-right-tools" class="hash-link" aria-label="Direct link to Choosing the Right Tools" title="Direct link to Choosing the Right Tools">​</a></h3>
<p>To cluster the data, several k-means clustering npm packages were looked at and finally, I finalized on using <a href="https://github.com/mljs/kmeans" target="_blank" rel="noopener noreferrer">ml-kmeans</a> combining it with <a href="https://github.com/mljs/distance" target="_blank" rel="noopener noreferrer">ml-distance</a> and <a href="https://github.com/simple-statistics/simple-statistics" target="_blank" rel="noopener noreferrer">simple-statistics</a>. Addtionally, to perform TF-IDF analysis on anime synopses, <a href="https://github.com/NaturalNode/natural" target="_blank" rel="noopener noreferrer">natural</a> was used alongside <a href="https://github.com/WorldBrain/remove-stopwords" target="_blank" rel="noopener noreferrer">remove-stopwords</a>, <a href="https://github.com/sindresorhus/word-list" target="_blank" rel="noopener noreferrer">word-list</a>, and <a href="https://github.com/FinNLP/lemmatizer" target="_blank" rel="noopener noreferrer">lemmatizer</a>.</p>
<p><strong>ml-distance</strong> offered various distance and similarity calculations and <strong>ml-kmeans</strong> allowed for the use of custom distance functions so this worked out really well for me.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-distance-functions">Understanding Distance Functions<a href="#understanding-distance-functions" class="hash-link" aria-label="Direct link to Understanding Distance Functions" title="Direct link to Understanding Distance Functions">​</a></h3>
<p>I tried to learn about some common distance functions used to cluster data such as euclidean, cosine, squared euclidean, manhattan, hamming, etc and through trial and error I experimented with all of the functions provided by <strong>ml-distance</strong>. Through my experiments, which involved applying various normalization techniques to anime properties and experimenting with different feature combinations, I discovered that the <strong>curse of dimensionality</strong> significantly impacted my results as the number of features in my feature tensors increased.</p>
<p>To combat the <strong>curse of dimensionality</strong>, I decided to use various normalization techniques, combinations of features and different weightings to these features. Additionally, I did try to reduce the number of features I used as originally, I wanted to see how the effect of all features together would be and it proved to be computationally expensive to compute for higher k values and harder to cluster effectively.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluating-clustering-effectiveness">Evaluating Clustering Effectiveness<a href="#evaluating-clustering-effectiveness" class="hash-link" aria-label="Direct link to Evaluating Clustering Effectiveness" title="Direct link to Evaluating Clustering Effectiveness">​</a></h3>
<p>I was able to assess the effectiveness of clustering by identifying several metrics that indicate the efficiency of clustering, including:</p>
<ul>
<li><strong>Within Cluster Sum of Squares (WCSS)</strong></li>
<li><strong>Elbow Method</strong></li>
<li><strong>Silhouette Score</strong></li>
</ul>
<p>While other metrics were available, my primary focus was on the Within Cluster Sum of Squares (WCSS) and the silhouette score when feasible. Fortunately, calculating the WCSS was straightforward with the assistance of <strong>ml-kmeans</strong>, and the silhouette score was computed using <strong>simple-statistics</strong>. However, the computation of the silhouette score became increasingly computationally intensive as the value of k increased, due to the large size of the feature tensors, leading me to prioritize the WCSS. My objective was to achieve the lowest WCSS and the highest silhouette score possible.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="best-distance-functions-for-the-dataset">Best Distance Functions for the Dataset<a href="#best-distance-functions-for-the-dataset" class="hash-link" aria-label="Direct link to Best Distance Functions for the Dataset" title="Direct link to Best Distance Functions for the Dataset">​</a></h3>
<p>From my experiments, I learned that given my data set, the following functions worked out the best:</p>
<ul>
<li><strong>Manhattan Distance</strong></li>
<li><strong>Dice Similarity</strong></li>
<li><strong>Jaccard Index</strong></li>
<li><strong>Gower&#x27;s Distance</strong></li>
<li><strong>Cosine Similarity</strong></li>
<li><strong>Sørensen–Dice coefficient</strong></li>
<li><strong>Tanimoto Index</strong></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="customizing-the-distance-function">Customizing the Distance Function<a href="#customizing-the-distance-function" class="hash-link" aria-label="Direct link to Customizing the Distance Function" title="Direct link to Customizing the Distance Function">​</a></h3>
<p>After additional experimentation, I attempted to develop a custom distance function by employing varying weights and combinations of distance measures for both categorical and numerical attributes. Initially, cosine similarity was employed, as it proved effective. After cosine similarity, I ended up using gower&#x27;s distance and that seemed to work out well purely based on the wcss values however, I learned later that this was due to the total number of values as the gower distance performed poorly as the number of values in the concatenated tensors for each anime increased, especially due to the amount of binary vectors.</p>
<p>To develop the current weighted distance function, I compared anime that were known to be similar, utilizing various distance measures with both the concatenated tensors as a whole and each individual feature tensor. This approach helped identify which properties most significantly increased the distance between each anime. At the same time, I was experimenting with different normalization techniques and feature tensor combinations. Eventually, I added weights which required a considerable amount of trial and error to achieve the current satisfactory level of recommendations as I had to experiment with different weightings for each property and different distance measures for each.</p>
<p>In the end, the manhattan distance was used for properties such as <code>type</code>, <code>rating</code>, and <code>demographics</code> where there was a numerical value and a need to seperate anime such as anime of type <code>TV</code> vs. <code>Movie</code>. The dice distance was used for all other properties such as <code>genres</code>, <code>themes</code>, <code>synopsis</code>, etc.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="future-experimentation">Future Experimentation<a href="#future-experimentation" class="hash-link" aria-label="Direct link to Future Experimentation" title="Direct link to Future Experimentation">​</a></h3>
<p>The K-means model currently uses a low k-value, <code>k = 10</code> which means that there are only 10 clusters and given the dataset size, that amounts to a significant amount of anime per cluster. Further experimentation is required to investigate larger k-values, which can better balance the system&#x27;s objectives and enhance the quality of recommendations. Moreover, the weights applied and the properties contain potential for further enhancement. Ideally, aiming for a larger number of clusters would enable a more accurate representation of the unique features of each anime grouping.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/kelbrum/normalize/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">📏 Normalizing Data</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/kelbrum/acknowledgments/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">✨ Acknowledgments</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#data-clustering-with-k-means" class="table-of-contents__link toc-highlight">Data Clustering with K-means</a><ul><li><a href="#identifying-clustering-algorithms" class="table-of-contents__link toc-highlight">Identifying Clustering Algorithms</a></li><li><a href="#choosing-the-right-tools" class="table-of-contents__link toc-highlight">Choosing the Right Tools</a></li><li><a href="#understanding-distance-functions" class="table-of-contents__link toc-highlight">Understanding Distance Functions</a></li><li><a href="#evaluating-clustering-effectiveness" class="table-of-contents__link toc-highlight">Evaluating Clustering Effectiveness</a></li><li><a href="#best-distance-functions-for-the-dataset" class="table-of-contents__link toc-highlight">Best Distance Functions for the Dataset</a></li><li><a href="#customizing-the-distance-function" class="table-of-contents__link toc-highlight">Customizing the Distance Function</a></li><li><a href="#future-experimentation" class="table-of-contents__link toc-highlight">Future Experimentation</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Getting Started</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/kelbrum/">Home</a></li><li class="footer__item"><a class="footer__link-item" href="/kelbrum/prerequisites/">Prerequisites</a></li><li class="footer__item"><a class="footer__link-item" href="/kelbrum/setup/">Setup</a></li><li class="footer__item"><a class="footer__link-item" href="/kelbrum/scripts/">Scripts</a></li></ul></div><div class="col footer__col"><div class="footer__title">Development</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/kelbrum/motivation/">Motivation</a></li><li class="footer__item"><a class="footer__link-item" href="/kelbrum/development/">Development Overview</a></li><li class="footer__item"><a class="footer__link-item" href="/kelbrum/stack/">Tech Stack</a></li><li class="footer__item"><a class="footer__link-item" href="/kelbrum/model/">Model Overview</a></li><li class="footer__item"><a class="footer__link-item" href="/kelbrum/normalize/">Normalizing Data</a></li><li class="footer__item"><a class="footer__link-item" href="/kelbrum/kmeans/">Data Clustering</a></li></ul></div><div class="col footer__col"><div class="footer__title">Conclusion</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/kelbrum/acknowledgments/">Acknowledgments</a></li><li class="footer__item"><a href="https://github.com/vikiru/kelbrum" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Kelbrum, Visakan Kirubakaran. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>